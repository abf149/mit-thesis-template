%% This is an example first chapter.  You should put chapter/appendix that you
%% write into a separate file, and add a line \include{yourfilename} to
%% main.tex, where `yourfilename.tex' is the name of the chapter/appendix file.
%% You can process specific files by typing their names in at the 
%% \files=
%% prompt when you run the file main.tex through LaTeX.
\chapter{Introduction}
\label{chapter:introduction}

Accelerating tensor operations is a significant research area with applications in deep neural network (DNN)-based machine learning inference\cite{eyeriss}\cite{eyerissv2}\cite{tpu}\cite{extensor}, scientific computing\cite{sci_tensor}, graph analytics\cite{mattson2013standards}, and data science\cite{mcauley2013hidden}\cite{kolda2009tensor}\cite{bader2008discussion}. Industrial demand for large scale\cite{tpu} and/or energy-efficient\cite{eyeriss} DNN deployment, combined with the demise of Moore's Law\cite{moore}, motivated the first generation of DNN-oriented tensor accelerators\cite{eyeriss}\cite{tpu}.

More recently, a new generation of hardware accelerators exploit tensor sparsity for improved scalability and efficiency\cite{ampere}\cite{eyerissv2}\cite{sparten}\cite{sparch}\cite{scnn}\cite{candles}\cite{extensor}. Tensor zero-compression \cite{szebook} \cite{sparseloop} \cite{extensor} and data-dependent computation strategies such as gating and skipping \cite{szebook} \cite{sparseloop} can meaningfully impact memory footprint, energy, area and total cycle time of an accelerator computation\cite{szebook}\cite{sparseloop}.

By removing elements, tensor zero-compression removes the regular structure that makes trivial operations such as iteration and co-iteration through tensor ranks feasible. While this problem is resolved with a layer of indirection (i.e. by adding \textit{metadata} that can recover the original coordinates of non-zero elements\cite{szebook}), the resulting sparse-tensor versions of these operations are sometimes more complex and resource intensive than their dense tensor counterparts\cite{extensor}\cite{sparten}\cite{sparch}\cite{ampere}. 

An additional avenue for exploiting sparsity is to optimize away arithmetic operations \cite{eyerissv2} \cite{sparten}\cite{extensor} \cite{sparch} \cite{szebook} \cite{sparseloop} (or quiesce compute during ineffectual operations (IneffOps)\cite{eyeriss}\cite{sparseloop}\cite{szebook}), the cost being a more complex microarchitecture that implements the sparsity-optimized arithmetic\cite{eyeriss}\cite{eyerissv2}. Generally speaking, to exploit sparsity for gains on key metrics, and still create a functionally correct accelerator, researchers frequently are compelled to specialize traversal\cite{szebook}\cite{extensor}, contraction\cite{gamma}\cite{eyerissv2}\cite{extensor}\cite{sparten}, or transposition/shuffle\cite{gamma} microarchitectures to be compatible with the architecture and its sparse representation format(s). Sometimes sparsity creates the need for microarchitectural functions that an equivalent dense tensor accelerator might not require for a similar workload, such as managing memory conflicts\cite{scnn}\cite{sparten}. New specialized microarchitectures for exploiting sparsity have played a key role in the advancement of sparse tensor accelerator research\cite{gamma}\cite{outerspace}\cite{extensor}\cite{sparch}\cite{outerspace}\cite{ampere}.

The Sparseloop\cite{sparseloop} paper introduced the Sparse Acceleration Feature (SAF) abstraction, which unifies prior work on sparse tensor accelerators into a taxonomy of sparsity optimizations. In addition to the SAF abstraction, Sparseloop\cite{sparseloop} also introduced a sparsity extension for Timeloop\cite{timeloop}, a pre-existing architectural modeling tool for dense tensor accelerators. 

Timeloop relies on a consistent set of abstractions for common architectural blocks, i.e. MAC, network-on-chip (NoC), Buffer (which can be subclassed as SRAM, DRAM, register file, ...), etc. Timeloop is used alongside Accelergy\cite{accelergy}, a pre-RTL analytical modeling framework, in order to associate architectural blocks with analytical energy/area models. 

Sparseloop incorporates the SAF abstraction into Timeloop\cite{sparseloop}. The user may specify one or more SAFs, and designate which architectural components (buffers, arithmetic) the SAFs are bound to. To estimate energy savings for a SAF optimization, the idealized SAF is lowered to align with the architectural component model it applies to, resulting in a decrease in the number of actions against that architectural component, and/or an adjustment to memory footprint and memory bandwidth utilization which accounts for sparse tensor representation formats. Broadly speaking, Sparseloop estimates the impact of SAF optimizations on architectural energy and area metrics.

Recall that sparse representation formats may increase the complexity of otherwise trivial operations. Architects of dense tensor accelerators might treat as insignificant the energy and area overhead incurred by SAF implementations, however Section~\ref{chapter:background} will show that as a proportion of total design area, the overhead costs of microarchitectures which implement SAFs (hereafter \textit{SAF microarchitectures}) \textit{may or may not} be very significant. This would suggest that SAF microarchitecture modeling is potentially critical: any benefit a SAF offers for architectural energy/area metrics, could in principle be offset by the energy/area overhead of the SAF microarchitecture.

In theory, Sparseloop could solve the SAF microarchitecture modeling issue, by lowering each SAF to align with a model of SAF microarchitecture energy-per-action and area, yielding an estimate of how the microarchitectural cost of the optimization trades off against its benefit in reducing architectural energy consumption. In practice, Sparseloop lacks abstractions or analytical models of SAF microarchitectural primitives and design topologies. When it comes to design-space exploration, SAF microarchitectures are neither factored into the computation energy estimate, nor into the accelerator area estimate.

Accelerator architectures benefit from tools like Timeloop and Sparseloop which facilitate design-space exploration and apples-to-apples comparison between accelerator designs. A framework of abstractions and models for SAF microarchitectures could increase the accuracy of cost comparisons between sparse tensor accelerators, and increase the likelihood that design-space exploration yields a sparse tensor accelerator that has low cost in practice.

This work attempts to synthesize a number of prior works into a concise, unified, and effective framework for doing research on SAF microarchitectures. The overall framework developed here comprises (1) a conceptual framework which facilitates concise description, modeling and design-space exploration for SAF microarchitectures, (2) a software framework, SAFTools, for compiling Sparseloop-style SAF descriptions into microarchitecture designs and analytical models, and (3) an extensible component library including specific SAF microarchitecture subcomponent designs as well as RTL to support implementation. SAFTools yields pre-RTL analytical models which are compatible with Accelergy and Sparseloop, and which hook into Accelergy architectural buffer models in such a way, that architectural buffer actions are translated into actions against a model of SAF microarchitecture energy. Furthermore, SAF microarchitecture area is factored into total design area. 

As a first step toward a set of consistent abstractions and modeling tools for SAF microarchitecture primitives - analogous to what is currently available for architectural modeling - it is hoped that this work will help enable researchers to systematically explore and compare sparsity optimizations in the design of sparse tensor accelerators. Section~\ref{chapter:background} provides background on SAF microarchitecture research and why it matters. Section~\ref{chapter:conceptual_framework} builds a novel conceptual framework for describing SAF microarchitectures. Section~\ref{chapter:rtl} overviews the RTL component designs (``RTL blocks'') which were written and characterized in order to support model development (additionally, these RTL blocks comprise the RTL library associated with this work.) Section~\ref{chapter:modeling} introduces abstractions for workload modeling, which aid in decoupling dataflow from SAF microarchitecture. Section~\ref{chapter:primitive_taxo_model} introduces the taxonomy of SAF microarchitecture primitives. Building on the previous section, Section~\ref{chapter:saf_microarchitectures} introduces the taxonomy of high-level SAF microarchitecture compound component blocks. Section~\ref{chapter:framework} overviews the architecture of the SAFtools software, component libraries, and RTL block libraries. Section~\ref{chapter:evaluation} evaluates some of SAFTools' capabilities. Section~\ref{chapter:case_studies} provides a case-study of using SAFTools to help design a sparse tensor accelerator with SIMD arithmetic.

%\begin{table}[ht]
%\resizebox{\textwidth}{!}{%
%\begin{tabular}{c|p{2.5cm}|p{2.5cm}|p{2.5cm}|p{2.5cm}}
% & Modeling speed & Accurate SAF $\mu$architecture modeling & Consistent SAF $\mu$architecture abstractions? & Open-source SAF $\mu$architecture RTL?\\ \hline \hline
%Architectural modeling frameworks & \textcolor{green}{\textbf{Fast}} & \textcolor{red}{\textbf{No}} & \textcolor{red}{\textbf{No}} & \textcolor{red}{\textbf{No}} \\ \hline
%Design-specific models & \textcolor{red}{\textbf{Slow}} & \textcolor{green}{\textbf{Yes}} & \textcolor{red}{\textbf{No}} & \textcolor{red}{\textbf{Limited}} \\ \hline
%$\mu$architecture taxonomy papers & \textcolor{red}{\textbf{N/A}} & \textcolor{red}{\textbf{No}} & \textcolor{red}{\textbf{Limited}} & \textcolor{red}{\textbf{No}} \\ \hline
%\textbf{This work} & \textcolor{green}{\textbf{Fast}} & \textcolor{green}{\textbf{Yes}} & \textcolor{green}{\textbf{Yes}} & \textcolor{green}{\textbf{Yes}} \\ \hline
%\end{tabular}
%}
%\label{tab:thiswork}
%\caption{SAFTools and the underlying SAF microarchitecture taxonomy enable fast, accurate SAF microarchitecture modeling based on a consistent set of abstractions.}
%\centering
%\end{table}